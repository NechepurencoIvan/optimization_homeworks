\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Домашнее задание № 3}
\author{Иван Нечепуренко }
\date{September 2018}

\usepackage{natbib}
\usepackage{graphicx}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools} % AMS
\usepackage[english,russian]{babel}	% локализация и переносы

\begin{document}

\maketitle

\section{Дивергенция Кульбака-Лейблера}

1) Для начала докажем вспомогательное утвержднение. Если
$\displaystyle a = \sum\limits_{i = 1}^n a_i, b = \sum\limits_{i = 1}^n b_i, a_i, b_i \geq 0 $,
то рассмотрим неравенство Йенсена для выпуклой функции $f(x) = x\log(x), x > 0 $:

$\displaystyle \sum\limits_{i=1}^n a_i \log\frac{a_i}{b_i} = 
\sum\limits_{i=1}^n b_i f\left(\frac{a_i}{b_i}\right) = 
b \sum\limits_{i=1}^n \frac{b_i}{b} f\left(\frac{a_i}{b_i}\right) \geq
b f\left(\sum\limits_{i=1}^n \frac{b_i}{b} \frac{a_i}{b_i}\right) = 
b f\left(\frac{a}{b}\right) = a \log\frac{a}{b}
$
($\displaystyle \frac{b_i}{b} \geq 0, \sum\limits_i b_i = b$ ). Волнующее нас неравенство:
$\displaystyle \sum\limits_{i=1}^n a_i \log\frac{a_i}{b_i} \geq a \log\frac{a}{b}$.
Стоит также заметить (достаточно проглядеть док-во ещё раз, и пользоваться строгим условием Йенсена), что равенство достигается только тогда, когда $a_i = cb_i$. 

Наконец, применим эту лемму для случая, когда $a_1(x) = \lambda p_1(x), a_2(x) = (1 - \lambda)p_2(x), b_1(x) = \lambda q_1(x), b_2(x) = (1 - \lambda)q_2(x)$, а также рассмотрим дискретный случай:

Тогда можно получить:

$$ \sum\limits_x (a_1\log\frac{a_1}{b_1} + a_2\log\frac{a_2}{b_2}) \geq 
\sum\limits_x (a_1 + a_2)\log\frac{a_1 + a_2}{b_1 + b_2}$$

Остается только выполнить обратную подстановку, получить $D_{KL}(\lambda p + (1 - \lambda)q) \leq \lambda D_{KL}(p)+ (1 - \lambda)D_{KL}(q)$. Непрерывный случай доказывается устремлением сумм Дарбу к бесконечности.

2), 3) Запишем неравенство Йенсена для вогнутого распределения:

$ \displaystyle
f(x_1\lambda_1 + .. x_n\lambda_n) \geq \lambda1f(x_1) + .. \lambda_nf(x_n), 
\lambda_i \geq 0, \sum\limits_{i = 1}^n \lambda_i = 1 
$

Рассматривая суммы Дарбу и переходя к пределу, мы можем получить следующее:

$$f\left(\int \lambda(t)x(t)dt\right) \geq \int f(x(t))\lambda(t)dt, \int\lambda(t)dt = 1, 
\lambda(t) \geq 0$$, 

Тогда фиксируем $\displaystyle f(x) = \log(x), \lambda(t) = q(t), x(t) = \frac{p(x)}{q(x)}$, и получаем:

$$ 0 = \log\left(\int p(x)\frac{q(x)}{p(x)}dx\right) \geq  \int p(x) \log\left(\frac{q(x)}{p(x)}\right) =
  -\int p(x) \log\frac{p(x)}{q(x)} = -D_{KL}(p || q) $$
  
 $$ D_{KL}(p || q) \geq 0$$

Остается понять, когда выполняется равенство $0$. $q(x) > 0$ на всем множестве, а это значит(из непрерывности), что необходимо и достаточно тождественное равенство $p(x)$ и $q(x)$(точнее, пропорциональность, но в коэффициента может выступать только $1$, иначе интеграл плотности не равен 1).

4) Так как неравенство не может выполняться всегда, к. к. мы можем взять, скажем, одинаковые распределения, нам достаточно просто привести контрпример. Выгодно рассмотреть дискретный случай(интегралы там вырождаются в суммы). Если множество, на котором $\{x | p(x) > 0\}$, является надмножеством $\{x | q(x) > 0\}$, то в одном случае значение будет бесконечностью, а в другом - нет. Впрочем, и для непрерывных распрелделений таких проблем не возникает.

\section{t-SNE алгоритм}  
Основая цель этого алгоритма - представить многомерные велины $X$ в роли двух- / трех- мерных $Y$, и при этом сохранить примерно растояния между ними. Многомерное евклидово расстояние между точками сначала заменяется на верояьтность того, что определенная точка будет выбрана соседней к данной, притом вероятность этого имеет гауссово распределение в зависимости от растояния до даной точки:
$$ p_{j |i } = \frac{exp(-||x_i - x_j||^2 / 2 \sigma_i^2)}
{exp(\sum_{k \neq i}-||x_i - x_k||^2 / 2 \sigma_i^2)}$$

Аналогичная оценка $q_{j|i}$ введена и в пространстве $Y$, считается по аналогичной формуле. Очевидно, нам хочется уменьшить различие между $p_{j |i }$ и $q_{j |i }$. Для этого и используется дивергенция Кульбака-Лейблера отн-но $p$ и $q$. Из-за несимметричности такой функции, ошибки неравноценны. Общими словами, мы можем с малой ценой ошибки приближать далекие точки, но вот отделение близких точек, наоборот, довольно дорого. Дисперсии же точек подбираются малыми в полтных скоплениях точек, и наоборот.

Использование ДКЛ выгодно тем, что градиент функции потерь выглядит весьма просто:
$$\frac{\partial Cost}{\partial y_i} = 2\sum\limits_j (p_{i|j} + p_{j|i} - q_{i|j} - q_{j|i}))(y_i - y_j)$$
Получается, как будто все точки действуют друг на друга некоторыми пружинками, и рано или поздно система стабилизируется. Далее, как правило, используется градиентный спуск. Но это - метод $SNE$, он не решает такой проблемы, как скученность точек.

$t-SNE$ же предполагает некоторый другой подход к решению проблемы. Во-первых,его функция потерь симметрична и имеет более простой градиент, во-вторых, гауссово распределение заменяется распредеклением Стьюдента, "тяжелые хвосты" которого помогают решать проблемму скученности. Симметричность берется из ф-ции
$\displaystyle p_{ij} = \frac{p_{i |j} + p_{j| i}}{2n}$, $n$ - общее кол-во точек. $y_{ij}$ считается по такой формуле, чтобы расположенные на среднем и далее расстоянии точки отталкивались сильнее - решается проблема скученности. 

Что же касается дискретной дивергенции, то она выражение для неё является очевидным переходом от интеграла к сумме, да и уже использовалась:
$\displaystyle D_{KL}(p||q) = \sum\limits_xp(x)\log\frac{p(x)}{q(x)}dx$
\section{ Перспективная выпуклость} 

Выпуклость множества определения проверяется просто по определению (см позже). Да и сама выпуклость проверяется по определению: фиксируем $\displaystyle \lambda \in [0, 1], x_1, x_2,$ $\displaystyle t_1, t_2: \frac{x_1}{t_1}, \frac{x_2}{t_2} \in dom f$. Расписываем:

$\displaystyle
g(\lambda x_1 + (1 - \lambda)x_2, \lambda t_1 + (1 - \lambda) t_2) = 
(\lambda t_1 + (1 - \lambda) t_2) f(\frac{\lambda x_1 + (1 - \lambda)x_2}{\lambda t_1 + (1 - \lambda) t_2}) =
(\lambda t_1 + (1 - \lambda) t_2) f(
\frac{\lambda t_1 x_1 / t_1}{\lambda t_1 + (1 - \lambda) t_2}
+
\frac{(1 - \lambda) t_2 x_2 / t_2}{\lambda t_1 + (1 - \lambda) t_2}
)
\leq 
\frac{(\lambda t_1 + (1 - \lambda) t_2)}{(\lambda t_1 + (1 - \lambda) t_2)}
(\lambda t_1 f(\frac{x_1}{t_1}) + (1 - \lambda) f(\frac{x_2}{t_2})) = 
\lambda g(x_1, t_1) + (1 - \lambda) g(x_2, t_2)
$

Мы здесь пользовались определением вапуклости для коэф-в $\displaystyle \frac{\lambda t_1}{\lambda t_1 + (1 - \lambda) t_2}$ и
$\displaystyle \frac{(1 - \lambda) t_2}{\lambda t_1 + (1 - \lambda) t_2}$, которые неотрицательны и в сумме дают 1. Кстати, с этими же коэфициентами берутся исходные точки и при доказательстве выпуклости множества определения.

\section{Обратное неравенство Йенсена}  
Кажется, для того чтобы левая часть неравенства была вообще определена, требуется дополнительно потребовать афинность области определения функции. Потребуем её. Далее, положим $x = \lambda_1x_1 + .. + \lambda_nx_n$. Далее, получаем:

\begin{align*} 
x &= \lambda_1x_1 + .. + \lambda_nx_n \\
-\lambda_1x_1 &= -x + \lambda_2x_2 + .. + \lambda_nx_n \\
x_1 &= \frac{x}{\lambda_1} - \frac{\lambda_2 x_2}{\lambda_1} - .. - \frac{\lambda_n x_n}{\lambda_1} \\
\end{align*}

Далее, остается заметить, что коэффициенты справа положительны и дают с сумме $1$,
и мы можем воспользоваться неравенством Йенсона:

\begin{align*} 
f(x_1) &\leq \frac{f(x)}{\lambda_1} - \frac{f(x_2)}{\lambda_1} - .. - \frac{f(x_n)}{\lambda_1} \\
f(x) &\geq \lambda_1 f(x_1) + .. + \lambda_n f(x_n)
\end{align*}

\section{Кратчайший путь в графе} Если в графе нет ребер, будем считать весы отсутствующх ребер бесконечными(наче непоняно, как их складывать  домножать на коэффценты). Заметим, что f(c) = $\min\limits_{l}(\sum\limits_{c_{i, j} \in l}c_{ij})$, где $l$ - пути, соединяющие данные точки. Суммы под знаком минимума являются и выпуклыми, и вогнутыми функциями(выпуклость области определения очевидна). Минмум сохраняет вогнутые функции, т. е. функция вогнута. Для выпуклости же есть контрпример: рассмотрим граф $(\{A, B, C, D\}, \{AB, AC, BD, CD\})$, ценовые функции
$c_{AB}, c_{AC}$, задающие соответствующим им ребрам 100, а остальным - 0. Самим функциям соответствуют пути цены 0, но вот их полусумма имеет вес $50$. Отсюда вытекает отсутствие выпуклости.
\end{document}
